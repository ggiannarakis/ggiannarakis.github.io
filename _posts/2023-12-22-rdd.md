---
title: "We do not have a control group! Or, do we?"
categories:
  - Blog
tags:
  - e-commerce
  - Experimentation
  - Causal Inference
header:
  teaser: /assets/images/discontinuity.jpg
---

When assessing the effect of an action with an experiment, a typical workflow will not only define
the technical steps for getting results; it will also introduce a checklist of conditions that should hold if
we want the results to be reliable. This includes things like proper randomization (and covariate balance),
full compliance, checks for sample ratio mismatch and more.

Of fundamental importance is the existence of a well-defined, properly-sized control group whose results
we will be comparing to those of the units that were treated. Normally, holding back a set of units from receiving
treatment is not a big deal - as this is most of the time temporary and the company is not missing out on much.

A case where the business perspective differs is that of marketing campaigns. Teams are frequently hesitant
to deprive users of marketing communications - as this is thought of as net negative for the business[^1],
and campaigns sometimes are simply unable to wait.
As a result, campaign experiments are frequently highly imbalanced (i.e., the treatment group is much larger than control).
This is not a big problem, as valid inference is still possible - albeit with lower statistical power.

What happens however when a marketing team pushes this paradigm to the extreme and simply contacts all eligible
users and therefore entirely omits a control group for the campaign?

This is a case I recently dealt with. As a new hire, I was not only working on adapting to a new job,
but also found myself in a place where no data scientist wants to be:
having to report causal inferences without access to a control group.

Coming from a job where interventions in the data were carried out by complex actors (nature / humans), I then had
very limited hope in successfully estimating the treatment effect. Business however, may be complex in how they operate,
but they are simple in terms of the goals they pursue and generally rational in how they go about achieving them.

The solution of my problem came from a topic much discussed and a power that keeps on giving: 
business understanding. In the case of the campaign, while no randomization happened and no control group was
established, the campaign was assigned based on a sharp cut-off of certain unit data.
This enabled the implementation of a custom Regression Discontinuity Design that made possible the estimation
of a Local Average Treatment Effect for the campaign. While quasi-experimental, this estimate was ultimately
good enough for campaign evaluation purposes, and synergized with the marketing team contacting the entire
user base with perfect timing.

This was a lesson learned for me too: causal inference of actors whose treatment assignment logic is known
may still be possible in the absence of a control group - or, alternatively, a control group may still exist outside
the "experiment". Life is certainly easier if we control the treatment assignment mechanism, even if no randomization
is employed[^2].


[^1]: If short-term revenue is the north star metric - which should not necessarily be [Kohavi & Longbotham 2011](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e11ad3691fa6abcad163945892e3bd17cb33dde9)
[^2]: A relevant [post](https://www.linkedin.com/feed/update/urn:li:activity:7104817647124439040?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7104817647124439040%29) can be found at the Linkedin profile of Matheus Facure, author of *"Causal Inference for the Brave and True"*. 

<figure>
  <img src="/assets/images/hp-office.jpg" alt="" style="width:90%">
</figure>